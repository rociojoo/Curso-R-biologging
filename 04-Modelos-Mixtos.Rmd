---
title: "Aplicación de R para datos de biologging"
subtitle: "GLMM en R"
author: "Rocío Joo"
date: "Nov.-Dic.  2020"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["chocolate-fonts", "hygge"]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---


# Objetivos de esta unidad 

 * Implementar modelos lineales generalizados mixtos en R e interpretar resultados
 
---

# Recordando teoría sobre modelos lineales generalizados mixtos

Empezaremos con un trabajo en grupo aleatorio sobre teoría de los modelos. 

[~40 minutos] para discutir y llenar el cuestionario cuyo link les enviaré.

--

Break [10 minutos]

--

Veamos las respuestas y conversemos. Luego colgaré las diapositivas.

 
---

# Explorando datos

Utilizaremos datos y algunos códigos de [ourcodingclub](https://ourcodingclub.github.io/tutorials/mixed-models/). 

Descargamos primero sus datos de dragones.

```{r, message=FALSE}
library(ggplot2) # plots
library(lme4) # lmer
library(MuMIn) # dredge

path_data <- "./data/"
path_plots <- "./img/"
```

```{r, eval = FALSE}
download.file(url = "https://raw.githubusercontent.com/ourcodingclub/CC-Linear-mixed-models/master/dragons.RData",
              destfile = paste0(path_data,"dragons.RData"))

```


---

# Explorando datos

```{r}
load(paste0(path_data,"dragons.RData"))
```

Los dragones tomaron un test de inteligencia (*testScore*) 
en 3 lugares (*sites*), ubicados en 
diferentes niveles de montañas (*mountainRange*), 
También se tomaron medidas corporales (*bodyLength*)

```{r}
head(dragons)

str(dragons)
```


---

# Regresión lineal

* Se piensa que hay una relación lineal entre la longitud corporal y 
el nivel de inteligencia. 
* Se hará una regresión lineal

```{r}
reg_lineal <- lm(formula = testScore ~ bodyLength, data = dragons)
summary(reg_lineal)
```

Pendiente: cambio en la variable respuesta por unidad de la variable independiente.

---

# Supuestos

* Hay una relación lineal entre variable dependiente e independiente(s).


```{r, fig.height = 5}
ggplot(data = dragons, mapping = aes(x = bodyLength, y = testScore)) +
  geom_point() +
  geom_smooth(method = "lm") # esto hace la regresión otra vez 
# la línea se podría suplantar con resultados de reg_lineal como
# geom_line(aes(y = reg_lineal$fitted.values))
```

---

# Supuestos

* Los residuales son normales con media 0 y varianza constante

```{r, fig.height = 4.5, fig.width = 5}
plot(reg_lineal, which = 1) 
```

* La media no es realmente cero
* La varianza no parece constante

---

# Supuestos

* Los residuales son normales con media 0 y varianza constante

```{r, fig.height = 3.5, fig.width = 4}
dragons$res <- residuals(reg_lineal)
ggplot(data = dragons, aes(x = res)) +
  geom_histogram() +
  theme_bw()
```
 * No parece muy normal, pero tampoco extremadamente lejos

---

# Supuestos

* Los residuales son normales con media 0 y varianza constante

```{r, fig.height = 4.5, fig.width = 5}
plot(reg_lineal, which = 2) 
```

 * No parece estar tan alejado de la normalidad.

---

# Supuestos 

* Combinando información de residuales y ajuste

```{r, fig.height = 3, fig.width = 4, warning = FALSE, message=FALSE}
dragons$predicted <- predict(reg_lineal) # valores predichos del modelo

ggplot(dragons, aes(x = bodyLength, y = testScore)) +
  geom_smooth(method = "lm", se = FALSE, color = "lightgrey") + # línea de regresión
  geom_segment(aes(xend = bodyLength, yend = predicted), alpha = .2) + # distancia entre observado y predicho
  geom_point(aes(color = res)) +  # colorear de acuerdo al tamaño del residual
  scale_color_viridis_c(begin = 0.2, end = 0.8, option = "plasma") +  # nueva escala de colores 
  # <
  geom_point(aes(y = predicted), shape = 1, cex = 0.5) + # dibujar los puntos predichos encima
  theme_bw()
```

---

# Ejemplos problemáticos

Los tomamos prestados de [Applied Statistics with R](https://daviddalpiaz.github.io/appliedstats/model-diagnostics.html#unusual-observations)

Varianza no constante

```{r, echo=FALSE}
sim_2 = function(sample_size = 500) {
  x = runif(n = sample_size) * 5
  y = 3 + 5 * x + rnorm(n = sample_size, mean = 0, sd = x)
  data.frame(x, y)
}
set.seed(42)
sim_data_2 = sim_2()
fit_2 = lm(y ~ x, data = sim_data_2)

```

```{r, fig.height = 4, fig.width = 5, warning=FALSE, message=FALSE, echo=FALSE}
ggplot(data = sim_data_2, mapping = aes(x = x, y = y)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE)
```
```{r, fig.height = 4, fig.width = 4.5, echo = FALSE}
plot(fit_2, which = 1) 
```

¿Qué hacer aquí?

---

# Ejemplos problemáticos

Los tomamos prestados de [Applied Statistics with R](https://daviddalpiaz.github.io/appliedstats/model-diagnostics.html#unusual-observations)

No linearidad

```{r, echo=FALSE}
sim_3 = function(sample_size = 500) {
  x = runif(n = sample_size) * 5
  y = 3 + 5 * x ^ 2 + rnorm(n = sample_size, mean = 0, sd = 5)
  data.frame(x, y)
}
set.seed(42)
sim_data_3 = sim_3()
fit_3 = lm(y ~ x, data = sim_data_3)

```

```{r, fig.height = 4, fig.width = 5, warning=FALSE, message=FALSE, echo=FALSE}
ggplot(data = sim_data_3, mapping = aes(x = x, y = y)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE)
```
```{r, fig.height = 4, fig.width = 4.5, echo = FALSE}
plot(fit_3, which = 1) 
```

¿Qué hacer aquí?

---

# Ejemplos problemáticos

Los tomamos prestados de [Applied Statistics with R](https://daviddalpiaz.github.io/appliedstats/model-diagnostics.html#unusual-observations)

No normalidad

```{r, fig.height = 4, fig.width = 10, warning=FALSE, message=FALSE, echo=FALSE}
par(mfrow = c(1, 3))
set.seed(420)
qqnorm(rt(10, df = 4))
qqline(rt(10, df = 4), col = "#56B4E9")
qqnorm(rt(25, df = 4))
qqline(rt(25, df = 4), col = "#56B4E9")
qqnorm(rt(100, df = 4))
qqline(rt(100, df = 4), col = "#56B4E9")
```

¿Qué hacer aquí?


---

# Outliers

Adaptamos ejemplos de [Applied Statistics with R](https://daviddalpiaz.github.io/appliedstats/model-diagnostics.html#unusual-observations).

Empezamos generando datos y modelándolos con una regresión lineal
```{r}
set.seed(42)
ex_data  = data.frame(x = 1:10,
                      y = 10:1 + rnorm(n = 10))
ex_model = lm(y ~ x, data = ex_data)
```

---

# Outliers

Añadamos un punto (x, y) y reajustemos una regresión lineal

```{r, fig.height = 2.5, fig.width = 3.5, warning = FALSE, message=FALSE}
point_1 = c(5.4, 11) # nuevo punto
ex_data_1 = rbind(ex_data, point_1) # añadiéndolo
model_1 = lm(y ~ x, data = ex_data_1) # nuevo modelo

ggplot(data = ex_data_1, aes(x = x, y = y)) +
  geom_point(color = "#999999") + # plotting all points
  geom_point(aes(x = x[1], y = y[1]), cex = 4, shape = 1) + # circunferencia para el nuevo punto
  geom_smooth(data = ex_data, method = "lm", se = FALSE, aes(color = "inicial")) + # línea de regresión del modelo inicial
  geom_smooth(method = "lm", se = FALSE, aes(color = "nuevo"), linetype = 2) + # línea de regresión del nuevo modelo
  scale_color_manual(name = "modelos", labels = c("inicial", "nuevo"), values = c("#56B4E9", "#E69F00")) +
theme_bw()
```
El punto "extraño" no genera mayores cambios en el modelo. 


---

# Outliers

Otro punto (x, y):

```{r, fig.height = 2.5, fig.width = 3.5, warning = FALSE, message=FALSE}
point_2 = c(18, -5.7) # nuevo punto
ex_data_2 = rbind(ex_data, point_2) # añadiéndolo
model_2 = lm(y ~ x, data = ex_data_2) # nuevo modelo

ggplot(data = ex_data_2, aes(x = x, y = y)) +
  geom_point(color = "#999999") + # plotting all points
  geom_point(aes(x = x[1], y = y[1]), cex = 4, shape = 1) + # circunferencia para el nuevo punto
  geom_smooth(data = ex_data, method = "lm", se = FALSE, aes(color = "inicial")) + # línea de regresión del modelo inicial
  geom_smooth(method = "lm", se = FALSE, aes(color = "nuevo"), linetype = 2) + # línea de regresión del nuevo modelo
  scale_color_manual(name = "modelos", labels = c("inicial", "nuevo"), values = c("#56B4E9", "#E69F00")) +
theme_bw()
```
El nuevo punto no influencia el modelo.

---

# Outliers

Otro punto (x, y):

```{r, fig.height = 2.5, fig.width = 3.5, warning = FALSE, message=FALSE}
point_3 = c(14, 5.1) # nuevo punto
ex_data_3 = rbind(ex_data, point_3) # añadiéndolo
model_3 = lm(y ~ x, data = ex_data_3) # nuevo modelo

ggplot(data = ex_data_3, aes(x = x, y = y)) +
  geom_point(color = "#999999") + # plotting all points
  geom_point(aes(x = x[1], y = y[1]), cex = 4, shape = 1) + # circunferencia para el nuevo punto
  geom_smooth(data = ex_data, method = "lm", se = FALSE, aes(color = "inicial")) + # línea de regresión del modelo inicial
  geom_smooth(method = "lm", se = FALSE, aes(color = "nuevo"), linetype = 2) + # línea de regresión del nuevo modelo
  scale_color_manual(name = "modelos", labels = c("inicial", "nuevo"), values = c("#56B4E9", "#E69F00")) +
theme_bw()
```
El nuevo modelo parece bastante distinto

---

# Supuestos

* ¿Por qué es importante chequearlos?

--

Porque en ellos se basan los modelos. Importante siempre. 
Necesario si el modelo es para explicar.

--

* ¿Por qué no usar tests?

--

Se puede, pero no hay que confiar a ciegas en un p-valor arbitrario. Ver referencias.


---

# Desafío

* En grupos aleatorios, tratar de identificar si hay algún punto que esté influyendo mucho
sobre la regresión ajustada a los datos de dragones.

* Dentro del GD: CURSO R-biologging/R-Rocío/04-Modelos-Mixtos/Grupos/Dragones/, 
  * Crear una carpeta ahí con sus iniciales, e.g. "CI-CZ"
  * Un google doc con sus nombres
  * Un script R
  * Archivo(s) de gráfico

[30 minutos]

---

# Modelos mixtos

* Otro escenario: se piensa que el nivel de inteligencia estaría explicado por 
la longitud corporal, pero que el resultado podría estar afectado por el nivel de 
montaña en el que se tomó cada muestra. 

* ¿Qué corresponde hacer aquí?

--

* Intentaremos explicar (buena) parte de la variación del nivel de inteligencia
por la longitud corporal (efecto fijo).

* Parte de la variación residual estaría asociada al nivel de montaña (efecto 
aleatorio).

* Intentaríamos modelar esta relación entre inteligencia y longitud corporal
controlando la variación debida a nivel de montaña.

--

```{r}
mod_mix <- lmer(formula = testScore ~ bodyLength + (1|mountainRange), data = dragons)
```

---

```{r}
summary(mod_mix)
```


---

# Modelos mixtos

```{r, fig.height = 3.5, fig.width = 4.5, warning = FALSE, message=FALSE}
dragons$predicted_modmix <- predict(mod_mix) # valores predichos del modelo 

ggplot(dragons, aes(x = bodyLength, y = testScore, color = mountainRange)) +
  geom_point(alpha = 0.5) +
  geom_line(aes(y = predicted_modmix), size = 1.5) +
  scale_color_brewer(palette = "Set2") +
  theme_bw()
```

Efectivamente no se observa una relación fuerte de testScore con bodyLength 
después de haber controlado por mountainRange. 

---

# Modelos mixtos

Residuales vs. valores predichos

```{r, fig.height = 3.5, fig.width = 4.5, warning = FALSE, message=FALSE}
plot(mod_mix, which = 1)
```

No se observan problemas de linealidad, media constante o varianza constante.

---

# Modelos mixtos

```{r, fig.height = 3.5, fig.width = 4.5, warning = FALSE, message=FALSE}
qqnorm(resid(mod_mix)) 
qqline(resid(mod_mix))  
```

O de normalidad. Quizás algún outlier.

¿Cómo interpretar estos resultados? Discutamos.

---

# Modelos mixtos

Un ejemplo más real que el de los dragones, de [Clay et al. (2020)](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/1365-2656.13267).

```{r}
path_file <- paste0(path_data, "BothSites_forwindexperienced.csv")
```

```{r, eval=FALSE}
download.file(url = "https://raw.githubusercontent.com/tommyclay/alba-wind-behaviour/master/Data_inputs/BothSites_forwindexperienced.csv", destfile = path_file)
```

```{r}
dat <- read.csv(file = path_file, na.strings = "NA")
head(dat)
```

---

# Modelos mixtos

```{r}
summary(dat)
```

El resumen ayuda a ver fácilmente las clases de datos y rangos de valores.

* Hay una línea por punto GPS. 
* No hay lon, lat o tiempo porque no son relevantes aquí.

---

# Modelos mixtos

Transformando a factor `ID`, `TripID` y `Year`

```{r}
var_fac <- c("ID", "TripID", "Year") # variables a transformar
dat[var_fac] <- lapply(dat[,var_fac], factor) # aplicar función factor a esas variables (columnas)

str(dat)
```


---

# Modelos mixtos

De [Clay et al. (2020)](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/1365-2656.13267):

* *We first assessed whether **wind speeds** experienced by birds
varied by **population** and **sex***

```{r, eval = FALSE}
WindSp ~ Site + Sex
```

(Site = population)

--

* *Wind **speed** was modelled as the response variable with a Gaussian error 
distribution, and the factors **population**, **sex**, their two-way 
**interaction** and **year** included as covariates.*

```{r, eval=FALSE}
lmer(WindSp ~ Site*Sex + Year)
```

--

* *A **random effect** of **trip identity** nested within **individual identity** 
was included to account for variation in the number and duration of trips per 
individual respectively*

```{r, eval=FALSE}
lmer(WindSp ~ Site*Sex + Year + (1|ID/TripID))
```

---

# Modelos mixtos

```{r}
mod_lin <- lmer(WindSp ~ Site*Sex + Year + (1|ID/TripID), data = dat, REML = TRUE)
```

* *We performed multi-model inference on the full set of 
predictor combinations and assessed the best-supported model as 
that with the lowest Akaike Information Criterion (AIC).*

* *As small differences in AIC are not considered to be meaningful (Burnham &
Anderson, 2002), if multiple models were within two AIC units, the
best model was deemed to be that which had the fewest number
of parameters (i.e. the most parsimonious) (Harrison et al., 2018).*

```{r, warning=FALSE, message=FALSE}
mod_lin_mv <- lmer(WindSp ~ Site*Sex + Year + (1|ID/TripID), 
                   data = dat, REML = FALSE)
# para comparar modelos es mejor hacerlo estimando por máxima verosimilitud
options(na.action = "na.fail") # sin esto nos da error "global model na action argument not set" 
# - así nos aseguramos de que la siguiente función nos arroje resultados si no hay
# valores faltantes. 
m_set <- dredge(mod_lin_mv) # Genera una tabla de selección de modelos con combinaciones de términos fijos
```


---

# Modelos mixtos

```{r}
m_set
```

El mejor modelo es el modelo completo. 

---

# Modelos mixtos 


```{r, fig.height = 3.5, fig.width = 4.5, warning = FALSE, message=FALSE}
plot(mod_lin, which = 1)
```
No se observan problemas de linealidad, media constante o varianza constante.

---

# Modelos mixtos

```{r, fig.height = 3.5, fig.width = 4.5, warning = FALSE, message=FALSE}
qqnorm(resid(mod_lin)) 
qqline(resid(mod_lin))  
```

No tan alejado de la normalidad. 


---

# Modelos mixtos

```{r, warning = FALSE, message=FALSE}
summary(mod_lin)
```

---

# Modelos mixtos

A ver, el mejor está compuesto por año, población y sexo como covariables 
(e interacción población y sexo) en efectos fijos. 

¿Qué tipo de gráfico nos ayudaría a interpretar las relaciones modeladas?

--

* Haremos una predicción de la velocidad del viento para cada combinación de
valores de sexo, población y año, las 3 covariables fijas.

```{r}
pred_df <- expand.grid(Sex = levels(dat$Sex), Site = levels(dat$Site), 
                       Year = levels(dat$Year)) 
prediccion <- predict(mod_lin, newdata = pred_df, re.form = NA) # re.form No efectos aleatorios
pred_df$fit <- prediccion
```

---

# Modelos mixtos

* Para mantenerlo simple, hacemos un boxplot de la velocidad del viento en función de población y sexo.

```{r, fig.height = 3.5, fig.width = 4.5, warning = FALSE, message=FALSE}
ggplot(data = pred_df, aes(x = Site, y = fit, color = Sex)) +
  geom_boxplot() +
  scale_color_brewer(palette = "Dark2") +
  ylab("Velocidad del viento predicha") +
  theme_bw()
```

---

# Modelos mixtos generalizados

Usaremos el ejemplo con datos cbpp del paquete `lme4`

```{r}
data(cbpp)
head(cbpp)
```
* Son datos de pleuroneumonía bovina contagiosa (`?cbpp`). 
* Estudio sobre 15 rebaños (herd).
* Herd: ID del rebaño
* Incidence: número de nuevos casos serológicos 
* Size: tamaño del rebaño en un período dado
* Period: factor de niveles del 1 al 4

---

# Modelos mixtos generalizados

Modelando la incidencia de pleuroneumonía en los rebaños debida al período, 
controlando por los rebaños muestreados. 

```{r}
(gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
              data = cbpp, family = binomial))
```

---

# Modelos mixtos generalizados

```{r}
summary(gm1)
```

---

# Modelos mixtos generalizados

```{r, fig.height = 3.5, fig.width = 4.5, warning = FALSE, message=FALSE}
plot(gm1, which = 1)
```

---

# Modelos mixtos generalizados

```{r, fig.height = 3.5, fig.width = 4.5, warning = FALSE, message=FALSE}
qqnorm(resid(gm1)) 
qqline(resid(gm1))  
```

---

# Modelos mixtos generalizados

```{r, fig.height = 3.5, fig.width = 4.5, warning = FALSE, message=FALSE}
pred_gm <- data.frame(period = factor(levels(cbpp$period)))
pred_gm$predict <- predict(gm1, newdata = pred_gm, re.form = NA, type = "response")

ggplot(data = cbpp, aes(x = period, y = incidence/size)) +
  geom_point(aes(color = herd)) +
  geom_point(data = pred_gm, aes(x = period, y = predict), cex = 4, shape = 1) +
  scale_color_viridis_d() +
  theme_bw()
```
              
---

# Su turno

En los grupos definidos, júntense para trabajar con sus datos:

* Según la pregunta de investigación, definan el/los modelo(s) más adecuado(s)
* Hacer el análisis en R
* * Dentro del GD: CURSO R-biologging/R-Rocío/04-Modelos-Mixtos/Grupos/DatosPropios/, 
  * Crear una carpeta ahí con sus iniciales, e.g. "CI-CZ"
  * Un google doc con sus nombres
  * Un script R
  * Archivo(s) de gráfico

[40 minutos]

---

# Bibliografía

Para preparar esta unidad se utilizó:

Material de: 
  * [Our coding club. Introduction to linear mixed models.](https://ourcodingclub.github.io/tutorials/mixed-models/)
  * [Applied statistics with R](https://daviddalpiaz.github.io/appliedstats/model-diagnostics.html#checking-assumptions)
  * [Visualizing residuals](https://drsimonj.svbtle.com/visualising-residuals)
  
Datos de: 
  * [Our coding club](https://github.com/ourcodingclub/CC-Linear-mixed-models)
  * [Clay et al. (2020). Sex-specific effects of wind on the flight decisions of a sexually-dimorphic soaring bird: data and R code. ](https://zenodo.org/record/3824065#.XrvM-mhKg2x)
  * Paquete `lme4`. Douglas Bates, Martin Maechler, Ben Bolker, Steve Walker (2015). Fitting Linear Mixed-Effects Models Using lme4. Journal of Statistical Software, 67(1), 1-48. doi:10.18637/jss.v067.i01.

---

# Bibliografía

Más:

* Paquetes para modelos estadísticos: [CRAN Task View: Analysis of Ecological and Environmental Data](https://cran.r-project.org/web/views/Environmetrics.html)

* Análisis de residuales: Paquete [`DHARMa`](https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html). 

* Tamaño del efecto: Nakagawa, S., & Cuthill, I. C. (2007). [Effect size, confidence interval and statistical significance: a practical guide for biologists](https://doi.org/10.1111/j.1469-185X.2007.00027.x). Biological Reviews, 82(4), 591–605. 

* Escoger modelos: Warton, D. I., Lyons, M., Stoklosa, J., & Ives, A. R. (2016). [Three points to consider when choosing a LM or GLM test for count data.](https://doi.org/10.1111/2041-210X.12552) Methods in Ecology and Evolution, 7(8), 882–890. 

* GAMs: [Introduction to Generalized Additive Models with R and mgcv](https://www.youtube.com/watch?v=sgw4cu8hrZM&t=9135s. Gavin Simpson. Jul. 30, 2020.

---

# Bibliografía

Aun más:

* P-valor y mejores prácticas estadísticas:
  * Anderson, D. R., Burnham, K. P., & Thompson, W. L. (2000). [Null Hypothesis Testing: Problems, Prevalence, and an Alternative](https://doi.org/10.2307/3803199). The Journal of Wildlife Management, 64(4), 912–923. JSTOR. 
  * Betensky, R. A. (2019). [The p-Value Requires Context, Not a Threshold](https://doi.org/10.1080/00031305.2018.1529624). The American Statistician, 73(sup1), 115–117. 
  * Goodman, S. N. (2019). [Why is Getting Rid of P-Values So Hard? Musings on Science and Statistics](https://doi.org/10.1080/00031305.2018.1558111). The American Statistician, 73(sup1), 26–30. 
  * Wasserstein, R. L., & Lazar, N. A. (2016). [The ASA Statement on p-Values: Context, Process, and Purpose](https://doi.org/10.1080/00031305.2016.1154108). The American Statistician, 70(2), 129–133. 
  * Zuur, A. F., & Ieno, E. N. (2016). [A protocol for conducting and presenting results of regression-type analyses.](https://doi.org/10.1111/2041-210X.12577) Methods in Ecology and Evolution, 7(6), 636–645. 
  * Fidler, F., Burgman, M. A., Cumming, G., Buttrose, R., & Thomason, N. (2006). [Impact of Criticism of Null-Hypothesis Significance Testing on Statistical Reporting Practices in Conservation Biology](https://doi.org/10.1111/j.1523-1739.2006.00525.x). Conservation Biology, 20(5), 1539–1544. 
  * Fidler, F., Geoff, C., Mark, B., & Neil, T. (2004). [Statistical reform in medicine, psychology and ecology](https://doi.org/10.1016/j.socec.2004.09.035). The Journal of Socio-Economics, 33(5), 615–630. 






